{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44029c7",
   "metadata": {},
   "source": [
    "### 0. Imports\n",
    "\n",
    "If this code block is failing, make sure you have all of the necessary packages installed. See `requirements.txt` in the root directory for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1cecef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec7692d",
   "metadata": {},
   "source": [
    "### 1. Set Variables and Paths\n",
    "\n",
    "`data_dir` should match where you have your data saved and `model_dir` is where your embedding models will be output. The cores variable sets the number of cores dedicated to parallelizing preprocessing. By default, half of your cores will be used. Set these to your preference accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9462cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "model_dir = \"../models\"\n",
    "cores = multiprocessing.cpu_count() // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8ec80",
   "metadata": {},
   "source": [
    "### 2. Identify Files for Model Training\n",
    "\n",
    "This will find **all** files in the `data_dir` specified. You will run into problems in later steps if there are any other files in the directory that cannot be opened as expected or are named in unexpected ways (data is expected to be named `sample_region.Sample_Country.eng.[clean|1].IN.gz`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21c9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [os.path.join(data_dir, file).replace(\"\\\\\", \"/\") for file in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, file))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3292343f",
   "metadata": {},
   "source": [
    "### 3. Function to Train and Save Embedding Space\n",
    "\n",
    "This function does the following:\n",
    "\n",
    "1. Opens the file into a Pandas dataframe\n",
    "2. Extracts the text column and preprocesses each sample using simple_preprocess from Gensim (throwing away the rest of the data)\n",
    "3. Uses Gensim Word2Vec to train a skip-gram model, iterating over the samples \n",
    "4. Saves the model to the given directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0e67b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def preprocess_text(texts):\n",
    "    return [simple_preprocess(text) for text in texts]\n",
    "\n",
    "def create_and_save_embedding_model(file_path, timestamp=None):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    country = os.path.basename(file_path).split(\".\")[1] # Extract country name from file name\n",
    "    model_path = os.path.join(model_dir, country + \".model\")\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Model for {country} already exists. Skipping...\")\n",
    "        return\n",
    "    print(f\"Processing {country}...\")\n",
    "\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8', errors='replace') as f:\n",
    "        df = pd.read_csv(f, encoding='utf-8', on_bad_lines='skip')\n",
    "    if timestamp is not None:\n",
    "        elapsed = time.time() - timestamp\n",
    "        minutes, seconds = divmod(int(elapsed), 60)\n",
    "        print(f\"\\tLoaded {df.shape[0]} rows of data ({minutes}:{seconds:02d})\")\n",
    "        timestamp = time.time()\n",
    "    \n",
    "    df = df['Text'].tolist()[1:2000000]  # limit to 2 million rows\n",
    "\n",
    "    \n",
    "    with Pool(processes=cores) as pool:\n",
    "        sentences = pool.map(simple_preprocess, df)\n",
    "    if timestamp is not None:\n",
    "        elapsed = time.time() - timestamp\n",
    "        minutes, seconds = divmod(int(elapsed), 60)\n",
    "        print(f\"\\tPreprocessed data ({minutes}:{seconds:02d})\")\n",
    "        timestamp = time.time()\n",
    "\n",
    "    del df\n",
    "    \n",
    "    model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=1, workers=4, epochs=1)\n",
    "    model.save(model_path)\n",
    "    if timestamp is not None:\n",
    "        elapsed = time.time() - timestamp\n",
    "        minutes, seconds = divmod(int(elapsed), 60)\n",
    "        print(f\"\\tWord2Vec model saved ({minutes}:{seconds:02d})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d6422",
   "metadata": {},
   "source": [
    "### 4. Loop Through and Train All Models\n",
    "\n",
    "Runs the embedding model code for each of the identified files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e066a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Nigeria already exists. Skipping...\n",
      "Model for Brazil already exists. Skipping...\n",
      "Processing Canada...\n",
      "\tLoaded 5638137 rows of data (1:28)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for file_path in file_paths:\n",
    "        create_and_save_embedding_model(file_path, timestamp=time.time())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
